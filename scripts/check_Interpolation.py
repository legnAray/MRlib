#!/usr/bin/env python3
import os
import sys
import pickle
import time
import glob

# ç¡®ä¿åœ¨å¯¼å…¥ torch/numpy ç­‰åº“ä¹‹å‰è®¾ç½®
os.environ["OMP_NUM_THREADS"] = "1"
sys.path.append(os.getcwd())

import numpy as np
import torch
import hydra
from omegaconf import DictConfig
import mujoco
import mujoco.viewer

# ä»Žæ‚¨æä¾›çš„ä»£ç ä¸­å¯¼å…¥å¿…è¦çš„ç§‘å­¦è®¡ç®—åº“
from scipy.interpolate import interp1d
from scipy.spatial.transform import Rotation, Slerp

# --- 1. è¿åŠ¨æ•°æ®å¤„ç†æ¨¡å— ---
class MotionProcessor:
    """å°è£…è¿åŠ¨æ•°æ®é‡é‡‡æ ·é€»è¾‘çš„ç±»"""

    def __init__(self, target_fps: int = 50):
        """
        åˆå§‹åŒ–å¤„ç†å™¨ã€‚
        Args:
            target_fps (int): é‡é‡‡æ ·åŽçš„ç›®æ ‡å¸§çŽ‡ã€‚
        """
        self.target_fps = target_fps
        self.simulation_dt = 1.0 / target_fps
        print(f"âœ… è¿åŠ¨å¤„ç†å™¨å·²åˆå§‹åŒ–ï¼Œç›®æ ‡å¸§çŽ‡: {self.target_fps} FPS (dt={self.simulation_dt:.4f}s)")

    def _resample_data_Rn(self, data: np.ndarray, original_keyframes, target_keyframes) -> np.ndarray:
        """ä½¿ç”¨çº¿æ€§æ’å€¼é‡é‡‡æ ·æ™®é€šå‘é‡æ•°æ® (ä¾‹å¦‚ä½ç½®)ã€‚"""
        # data çš„å½¢çŠ¶æ˜¯ (T, D)
        f = interp1d(original_keyframes, data, axis=0)
        return f(target_keyframes)

    def _resample_data_SO3(self, raw_quaternions: np.ndarray, original_keyframes, target_keyframes) -> np.ndarray:
        rotations = Rotation.from_quat(raw_quaternions)
        slerp = Slerp(original_keyframes, rotations)
        resampled_rotations = slerp(target_keyframes)
        return resampled_rotations.as_quat()

    def _process_single_motion(self, motion_data: dict) -> dict:
        """å¤„ç†å•ä¸ªè¿åŠ¨åºåˆ—ï¼Œå°†å…¶é‡é‡‡æ ·åˆ°ç›®æ ‡å¸§çŽ‡ã€‚"""
        # æå–æ ¸å¿ƒæ•°æ®
        joint_positions_raw = motion_data["dof_increment"]
        root_positions_raw = motion_data["root_trans_offset"]
        root_quats_raw = motion_data["root_rot"]  # æ ¼å¼: xyzw
        original_fps = motion_data["fps"]

        # è®¡ç®—åŽŸå§‹å’Œç›®æ ‡æ—¶é—´åºåˆ—
        dt_orig = 1.0 / original_fps
        T_orig = len(joint_positions_raw)
        t_orig = np.linspace(0, (T_orig - 1) * dt_orig, T_orig)

        T_new = int(T_orig * dt_orig / 0.02)
        t_new = np.linspace(0, (T_orig - 1) * dt_orig, T_new)

        # é‡é‡‡æ ·æ‰€æœ‰éœ€è¦çš„æ•°æ®
        resampled_joint_positions = self._resample_data_Rn(joint_positions_raw, t_orig, t_new)
        resampled_base_positions = self._resample_data_Rn(root_positions_raw, t_orig, t_new)
        resampled_base_orientations = self._resample_data_SO3(root_quats_raw, t_orig, t_new)

        # æž„å»ºæ–°çš„ã€åªåŒ…å«æ ¸å¿ƒæ’­æ”¾æ•°æ®çš„å­—å…¸
        new_motion = {
            "dof_increment": resampled_joint_positions,
            "root_trans_offset": resampled_base_positions,
            "root_rot": resampled_base_orientations,
            "fps": self.target_fps,
            "default_joint_angles": motion_data.get("default_joint_angles", 0) # ä¿ç•™é»˜è®¤è§’åº¦
        }
        return new_motion

    def process_dataset(self, original_dataset: dict) -> dict:
        """
        å¤„ç†æ•´ä¸ªæ•°æ®é›†ï¼Œå¯¹å…¶ä¸­æ¯ä¸ªåŠ¨ä½œè¿›è¡Œé‡é‡‡æ ·ã€‚
        """
        print("\n" + "="*50)
        print("ðŸš€ å¼€å§‹å¤„ç†æ•´ä¸ªæ•°æ®é›†...")
        resampled_dataset = {}
        for motion_key, motion_data in original_dataset.items():
            print(f"  å¤„ç†åŠ¨ä½œ: '{motion_key}'")
            try:
                new_motion = self._process_single_motion(motion_data)
                resampled_dataset[motion_key] = new_motion
            except Exception as e:
                print(f"    âŒ å¤„ç† '{motion_key}' æ—¶å‘ç”Ÿé”™è¯¯: {e}")

        print("ðŸŽ‰ æ•°æ®é›†å¤„ç†å®Œæˆ!")
        print("="*50 + "\n")
        return resampled_dataset


# --- 2. ç®€åŒ–çš„æ’­æ”¾å™¨ ---
# å…¨å±€å˜é‡ç”¨äºŽé”®ç›˜å›žè°ƒ
paused = False
motion_id = 0
time_step = 0.0
motion_data_keys = []
motion_data_resampled = {}


def key_callback(keycode):
    """ç®€åŒ–çš„é”®ç›˜å›žè°ƒå‡½æ•°"""
    global paused, motion_id, time_step
    key_char = chr(keycode)

    if key_char == ' ':
        paused = not paused
        print("æ’­æ”¾å·²æš‚åœ" if paused else "æ’­æ”¾å·²ç»§ç»­")
    elif key_char == 'R':
        time_step = 0
        print("é‡ç½®å½“å‰åŠ¨ä½œ")
    elif key_char == 'Q':
        motion_id = max(0, motion_id - 1)
        time_step = 0
        print(f"åˆ‡æ¢åˆ°ä¸Šä¸€ä¸ªåŠ¨ä½œ: {motion_data_keys[motion_id]}")
    elif key_char == 'E':
        motion_id = min(len(motion_data_keys) - 1, motion_id + 1)
        time_step = 0
        print(f"åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªåŠ¨ä½œ: {motion_data_keys[motion_id]}")
    else:
        # å…¶ä»–æŒ‰é”®å¯ä»¥ä¿ç•™æˆ–ç§»é™¤ï¼Œè¿™é‡Œåªä¿ç•™æœ€æ ¸å¿ƒçš„
        pass

@hydra.main(version_base=None, config_path="../cfg", config_name="config")
def main(cfg: DictConfig) -> None:
    global paused, motion_id, time_step, motion_data_keys, motion_data_resampled

    # --- A. åŠ è½½å’Œå¤„ç†æ•°æ® ---

    # è‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°çš„åŽŸå§‹è¿åŠ¨æ–‡ä»¶
    pkl_pattern = f"{cfg.output_path}/{cfg.robot.humanoid_type}/*.pkl"
    pkl_files = glob.glob(pkl_pattern)
    if not pkl_files:
        print(f"é”™è¯¯: åœ¨ {cfg.output_path}/{cfg.robot.humanoid_type}/ ä¸­æœªæ‰¾åˆ°åŽŸå§‹è¿åŠ¨æ–‡ä»¶ã€‚")
        return

    original_motion_file = max(pkl_files, key=os.path.getmtime)
    print(f"ðŸ“– æ­£åœ¨åŠ è½½åŽŸå§‹è¿åŠ¨æ–‡ä»¶: {original_motion_file}")

    with open(original_motion_file, "rb") as f:
        motion_data_original = pickle.load(f)

    # å®žä¾‹åŒ–å¤„ç†å™¨å¹¶å¤„ç†æ•°æ®
    TARGET_FPS = 50
    processor = MotionProcessor(target_fps=TARGET_FPS)
    motion_data_resampled = processor.process_dataset(motion_data_original)

    # ä¿å­˜å¤„ç†åŽçš„æ–‡ä»¶
    output_filename = os.path.join(
        os.path.dirname(original_motion_file),
        f"{os.path.splitext(os.path.basename(original_motion_file))[0]}_resampled_{TARGET_FPS}fps.pkl"
    )
    print(f"ðŸ’¾ æ­£åœ¨ä¿å­˜é‡é‡‡æ ·åŽçš„æ•°æ®é›†åˆ°: {output_filename}")
    with open(output_filename, "wb") as f:
        pickle.dump(motion_data_resampled, f)
    print("ä¿å­˜æˆåŠŸ!")

    motion_data_keys = list(motion_data_resampled.keys())
    if not motion_data_keys:
        print("é”™è¯¯: é‡é‡‡æ ·åŽçš„æ•°æ®é›†ä¸­æ²¡æœ‰ä»»ä½•åŠ¨ä½œã€‚")
        return

    # --- B. åˆå§‹åŒ–MuJoCoæ’­æ”¾å™¨ ---
    humanoid_xml = cfg.robot.asset.assetFileName
    mj_model = mujoco.MjModel.from_xml_path(humanoid_xml)

    # è®¾ç½®æ¨¡æ‹Ÿå™¨çš„ timestep ä»¥åŒ¹é…æˆ‘ä»¬æ–°çš„å¸§çŽ‡
    dt = 1.0 / TARGET_FPS
    mj_model.opt.timestep = dt

    mj_data = mujoco.MjData(mj_model)

    print("\n" + "="*50)
    print("ðŸŽ® æ’­æ”¾å™¨æŽ§åˆ¶:")
    print("  ç©ºæ ¼: æš‚åœ/ç»§ç»­")
    print("  R:   é‡ç½®å½“å‰åŠ¨ä½œ")
    print("  Q:   ä¸Šä¸€ä¸ªåŠ¨ä½œ")
    print("  E:   ä¸‹ä¸€ä¸ªåŠ¨ä½œ")
    print("="*50 + "\n")

    # --- C. å¯åŠ¨æ’­æ”¾å™¨å’Œä¸»å¾ªçŽ¯ ---
    with mujoco.viewer.launch_passive(mj_model, mj_data, key_callback=key_callback) as viewer:
        while viewer.is_running():
            step_start = time.time()

            # èŽ·å–å½“å‰åŠ¨ä½œ
            curr_motion_key = motion_data_keys[motion_id]
            curr_motion = motion_data_resampled[curr_motion_key]

            max_frames = len(curr_motion["root_rot"])
            curr_frame_idx = int(time_step / dt) % max_frames

            # æ›´æ–°æ¨¡åž‹çŠ¶æ€
            mj_data.qpos[:3] = curr_motion["root_trans_offset"][curr_frame_idx]
            # MuJoCoå››å…ƒæ•°é¡ºåºä¸º w,x,y,z; æˆ‘ä»¬çš„æ•°æ®æ˜¯ x,y,z,w
            mj_data.qpos[3:7] = curr_motion["root_rot"][curr_frame_idx][[3, 0, 1, 2]]

            # å…³èŠ‚è§’åº¦ = å¢žé‡ + é»˜è®¤å€¼
            default_angles = curr_motion.get("default_joint_angles", 0)
            mj_data.qpos[7:] = curr_motion["dof_increment"][curr_frame_idx] + default_angles

            mujoco.mj_forward(mj_model, mj_data)

            # ç®€å•çš„ä¿¡æ¯æ‰“å°
            if not paused and curr_frame_idx % TARGET_FPS == 0: # æ¯ç§’æ‰“å°ä¸€æ¬¡
                print(f"  â–¶ï¸ æ’­æ”¾ä¸­: {curr_motion_key} | å¸§: {curr_frame_idx}/{max_frames}", end='\r')

            # æ›´æ–°æ—¶é—´æ­¥
            if not paused:
                time_step += dt

            # åŒæ­¥æ¸²æŸ“
            viewer.sync()

            # æŽ§åˆ¶æ’­æ”¾é€Ÿåº¦ä»¥åŒ¹é…çœŸå®žæ—¶é—´
            time_until_next_step = dt - (time.time() - step_start)
            if time_until_next_step > 0:
                time.sleep(time_until_next_step)

if __name__ == "__main__":
    main()