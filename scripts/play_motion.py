import os
os.environ["OMP_NUM_THREADS"] = "1"

import sys
import time
import argparse
import pdb
import os.path as osp

sys.path.append(os.getcwd())

from mrlib.poselib.skeleton.skeleton3d import SkeletonTree
import torch

import numpy as np
import math
from copy import deepcopy
from collections import defaultdict
import mujoco
import mujoco.viewer
from scipy.spatial.transform import Rotation as sRot
import joblib
import hydra
from omegaconf import DictConfig, OmegaConf
from collections import Counter

def add_visual_capsule(scene, point1, point2, radius, rgba):
    """Adds one capsule to an mjvScene."""
    if scene.ngeom >= scene.maxgeom:
        return
    scene.ngeom += 1  # increment ngeom
    # initialise a new capsule, add it to the scene using mjv_makeConnector
    mujoco.mjv_initGeom(scene.geoms[scene.ngeom-1],
                        mujoco.mjtGeom.mjGEOM_CAPSULE, np.zeros(3),
                        np.zeros(3), np.zeros(9), rgba.astype(np.float32))
    mujoco.mjv_makeConnector(scene.geoms[scene.ngeom-1],
                            mujoco.mjtGeom.mjGEOM_CAPSULE, radius,
                            point1[0], point1[1], point1[2],
                            point2[0], point2[1], point2[2])

def analyze_motion_stats(motion_data, current_motion_key=None):
    """åˆ†æåŠ¨ä½œåºåˆ—çš„ç»Ÿè®¡ä¿¡æ¯
    
    Args:
        motion_data: è¿åŠ¨æ•°æ®å­—å…¸
        current_motion_key: å¦‚æœæŒ‡å®šï¼Œåªåˆ†æå½“å‰åŠ¨ä½œï¼›å¦åˆ™åˆ†ææ‰€æœ‰åŠ¨ä½œ
    """
    print("\n" + "="*80)
    if current_motion_key:
        print(f"ğŸ“Š å½“å‰åŠ¨ä½œç»Ÿè®¡åˆ†æ: {current_motion_key}")
    else:
        print("ğŸ“Š æ‰€æœ‰åŠ¨ä½œåºåˆ—ç»Ÿè®¡åˆ†æ")
    print("="*80)
    
    motion_type_names = {
        0: "åŸåœ°è¸æ­¥", 1: "å·¦è½¬è¡Œèµ°", 2: "å³è½¬è¡Œèµ°", 3: "ç›´çº¿è¡Œèµ°",
        4: "å·¦è½¬è·‘æ­¥", 5: "å³è½¬è·‘æ­¥", 6: "ç›´çº¿è·‘æ­¥", 
        7: "ç«™ç«‹", 8: "è¹²ä¸‹", 9: "æœªçŸ¥"
    }
    
    # æ ¹æ®å‚æ•°å†³å®šåˆ†æå“ªäº›åŠ¨ä½œ
    if current_motion_key and current_motion_key in motion_data:
        motions_to_analyze = {current_motion_key: motion_data[current_motion_key]}
    else:
        motions_to_analyze = motion_data
    
    for motion_key, motion in motions_to_analyze.items():
        print(f"\nğŸ¬ åŠ¨ä½œ: {motion_key}")
        print("-" * 60)
        
        if 'task_info' not in motion:
            print("âŒ æ— task_infoæ•°æ®")
            continue
            
        task_info = motion['task_info']
        target_vel = task_info['target_vel']
        motion_types = task_info['motion_type']
        
        # è®¡ç®—æœ€å¤§é€Ÿåº¦
        min_vel_x = np.min(target_vel[:, 0])
        max_vel_x = np.max(target_vel[:, 0])
        print(f"Xè½´(å‰è¿›): èŒƒå›´=[{min_vel_x:.3f}, {max_vel_x:.3f}] m/s")
        min_vel_y = np.min(target_vel[:, 1])
        max_vel_y = np.max(target_vel[:, 1])
        print(f"Yè½´(æ¨ªå‘): èŒƒå›´=[{min_vel_y:.3f}, {max_vel_y:.3f}] m/s")
        min_vel_z = np.min(target_vel[:, 2])
        max_vel_z = np.max(target_vel[:, 2])
        print(f"Zè½´(è½¬å‘): èŒƒå›´=[{min_vel_z:.3f}, {max_vel_z:.3f}] rad/s")
        
        # è®¡ç®—çœŸå®å¹³å‡å€¼ï¼ˆå¸¦ç¬¦å·ï¼‰å’Œç»å¯¹å€¼ç»Ÿè®¡
        avg_vel_x = np.mean(target_vel[:, 0])
        avg_vel_y = np.mean(target_vel[:, 1])
        avg_vel_z = np.mean(target_vel[:, 2])
        
        # è®¡ç®—ç»å¯¹å€¼æœ€å¤§å€¼ï¼ˆç”¨äºæ˜¾ç¤ºæœ€å¤§ç»å¯¹é€Ÿåº¦ï¼‰
        max_abs_vel_x = np.max(np.abs(target_vel[:, 0]))
        max_abs_vel_y = np.max(np.abs(target_vel[:, 1]))
        max_abs_vel_z = np.max(np.abs(target_vel[:, 2]))
        
        # è®¡ç®—æ€»é€Ÿåº¦èŒƒå›´
        total_speeds = np.sqrt(target_vel[:, 0]**2 + target_vel[:, 1]**2)
        max_total_speed = np.max(total_speeds)
        avg_total_speed = np.mean(total_speeds)
        
        print(f"ğŸ¯ é€Ÿåº¦åˆ†æ:")
        print(f"   Xè½´(å‰è¿›): æœ€å¤§ç»å¯¹å€¼={max_abs_vel_x:6.3f} m/s, å¹³å‡={avg_vel_x:+6.3f} m/s")
        print(f"   Yè½´(æ¨ªå‘): æœ€å¤§ç»å¯¹å€¼={max_abs_vel_y:6.3f} m/s, å¹³å‡={avg_vel_y:+6.3f} m/s")
        print(f"   Zè½´(è½¬å‘): æœ€å¤§ç»å¯¹å€¼={max_abs_vel_z:6.3f} rad/s, å¹³å‡={avg_vel_z:+6.3f} rad/s")
        print(f"   æ€»é€Ÿåº¦:    æœ€å¤§={max_total_speed:6.3f} m/s, å¹³å‡={avg_total_speed:6.3f} m/s")
        
        # ç»Ÿè®¡è¿åŠ¨ç±»å‹å æ¯”
        type_counts = Counter(motion_types)
        total_frames = len(motion_types)
        
        print(f"ğŸƒ è¿åŠ¨ç±»å‹å æ¯” (æ€»å¸§æ•°: {total_frames}):")
        for motion_type in sorted(type_counts.keys()):
            count = type_counts[motion_type]
            percentage = (count / total_frames) * 100
            type_name = motion_type_names.get(motion_type, f"ç±»å‹{motion_type}")
            print(f"   {motion_type:2d} ({type_name:8s}): {count:4d}å¸§ ({percentage:5.1f}%)")
        
        # åˆ†æé€Ÿåº¦åˆ†å¸ƒ
        high_speed_frames = np.sum(total_speeds > 1.0)
        medium_speed_frames = np.sum((total_speeds > 0.3) & (total_speeds <= 1.0))
        low_speed_frames = np.sum(total_speeds <= 0.3)
        
        print(f"ğŸš€ é€Ÿåº¦åˆ†å¸ƒ:")
        print(f"   é«˜é€Ÿ(>1.0m/s):   {high_speed_frames:4d}å¸§ ({high_speed_frames/total_frames*100:5.1f}%)")
        print(f"   ä¸­é€Ÿ(0.3-1.0m/s): {medium_speed_frames:4d}å¸§ ({medium_speed_frames/total_frames*100:5.1f}%)")
        print(f"   ä½é€Ÿ(<=0.3m/s):  {low_speed_frames:4d}å¸§ ({low_speed_frames/total_frames*100:5.1f}%)")
        
        # åˆ†æè½¬å‘ï¼Œä½¿ç”¨ä¸åˆ†ç±»é€»è¾‘ä¸€è‡´çš„é˜ˆå€¼
        strong_turn_frames = np.sum(np.abs(target_vel[:, 2]) > 0.8)  # æ˜æ˜¾è½¬å‘
        medium_turn_frames = np.sum((np.abs(target_vel[:, 2]) > 0.3) & (np.abs(target_vel[:, 2]) <= 0.8))  # ä¸­ç­‰è½¬å‘
        weak_turn_frames = np.sum((np.abs(target_vel[:, 2]) > 0.1) & (np.abs(target_vel[:, 2]) <= 0.3))  # è½»å¾®è½¬å‘
        straight_frames = np.sum(np.abs(target_vel[:, 2]) <= 0.1)  # åŸºæœ¬ç›´è¡Œ
        
        print(f"ğŸ”„ è½¬å‘åˆ†å¸ƒ (æ–°é˜ˆå€¼: æ˜æ˜¾è½¬å‘>0.8rad/s):")
        print(f"   æ˜æ˜¾è½¬å‘(>0.8rad/s):   {strong_turn_frames:4d}å¸§ ({strong_turn_frames/total_frames*100:5.1f}%)")
        print(f"   ä¸­ç­‰è½¬å‘(0.3-0.8rad/s): {medium_turn_frames:4d}å¸§ ({medium_turn_frames/total_frames*100:5.1f}%)")
        print(f"   è½»å¾®è½¬å‘(0.1-0.3rad/s): {weak_turn_frames:4d}å¸§ ({weak_turn_frames/total_frames*100:5.1f}%)")
        print(f"   åŸºæœ¬ç›´è¡Œ(<=0.1rad/s):  {straight_frames:4d}å¸§ ({straight_frames/total_frames*100:5.1f}%)")
        
        # æ–°å¢ï¼šåˆ†ææœºå™¨äººåæ ‡ç³»ä¸‹çš„è¿åŠ¨æ–¹å‘
        print(f"ğŸ§­ è¿åŠ¨æ–¹å‘åˆ†æ:")
        forward_frames = np.sum(target_vel[:, 0] > 0.1)   # å‰è¿›
        backward_frames = np.sum(target_vel[:, 0] < -0.1)  # åé€€
        left_frames = np.sum(target_vel[:, 1] > 0.1)      # å·¦ç§»
        right_frames = np.sum(target_vel[:, 1] < -0.1)    # å³ç§»
        static_frames = np.sum((np.abs(target_vel[:, 0]) <= 0.1) & (np.abs(target_vel[:, 1]) <= 0.1))  # é™æ­¢
        
        print(f"   å‰è¿›(+X>0.1m/s):     {forward_frames:4d}å¸§ ({forward_frames/total_frames*100:5.1f}%)")
        print(f"   åé€€(-X<-0.1m/s):    {backward_frames:4d}å¸§ ({backward_frames/total_frames*100:5.1f}%)")
        print(f"   å·¦ç§»(+Y>0.1m/s):     {left_frames:4d}å¸§ ({left_frames/total_frames*100:5.1f}%)")
        print(f"   å³ç§»(-Y<-0.1m/s):    {right_frames:4d}å¸§ ({right_frames/total_frames*100:5.1f}%)")
        print(f"   é™æ­¢(|XY|<=0.1m/s):  {static_frames:4d}å¸§ ({static_frames/total_frames*100:5.1f}%)")
    
    print("\n" + "="*80)

def key_call_back(keycode):
    global curr_start, num_motions, motion_id, motion_acc, time_step, dt, paused, motion_data_keys, info_display_interval, motion_data, motion_id
    if chr(keycode) == "R":
        print("Reset")
        time_step = 0
    elif chr(keycode) == " ":
        print("Paused")
        paused = not paused
    elif chr(keycode) == "Q":
        print("previous")
        motion_id = max(0, motion_id - 1)
        curr_motion_key = motion_data_keys[motion_id]
        print(f"åˆ‡æ¢åˆ°è¿åŠ¨: {curr_motion_key}")
    elif chr(keycode) == "E":
        print("next")
        motion_id = min(len(motion_data_keys) - 1, motion_id + 1)
        curr_motion_key = motion_data_keys[motion_id]
        print(f"åˆ‡æ¢åˆ°è¿åŠ¨: {curr_motion_key}")
    elif chr(keycode) == "I":
        # åˆ‡æ¢ä¿¡æ¯æ˜¾ç¤ºé¢‘ç‡
        if info_display_interval == 10:
            info_display_interval = 30  # æ¯ç§’æ˜¾ç¤ºä¸€æ¬¡
            print("ğŸ“Š Task Infoæ˜¾ç¤ºé¢‘ç‡: æ¯30å¸§(1ç§’)")
        elif info_display_interval == 30:
            info_display_interval = 1   # æ¯å¸§æ˜¾ç¤º
            print("ğŸ“Š Task Infoæ˜¾ç¤ºé¢‘ç‡: æ¯å¸§")
        else:
            info_display_interval = 10  # æ¯10å¸§æ˜¾ç¤º
            print("ğŸ“Š Task Infoæ˜¾ç¤ºé¢‘ç‡: æ¯10å¸§")
    elif chr(keycode) == "S":
        # æ˜¾ç¤ºå½“å‰åŠ¨ä½œç»Ÿè®¡ä¿¡æ¯
        curr_motion_key = motion_data_keys[motion_id]
        print(f"ğŸ“Š æ˜¾ç¤ºå½“å‰åŠ¨ä½œç»Ÿè®¡ä¿¡æ¯: {curr_motion_key}")
        analyze_motion_stats(motion_data, curr_motion_key)
    elif chr(keycode) == "A":
        # æ˜¾ç¤ºæ‰€æœ‰åŠ¨ä½œç»Ÿè®¡ä¿¡æ¯
        print("ğŸ“Š æ˜¾ç¤ºæ‰€æœ‰åŠ¨ä½œç»Ÿè®¡ä¿¡æ¯...")
        analyze_motion_stats(motion_data)
    else:
        print("æœªæ˜ å°„çš„æŒ‰é”®:", chr(keycode))
    
    
@hydra.main(version_base=None, config_path="../cfg", config_name="config")
def main(cfg : DictConfig) -> None:
    global curr_start, num_motions, motion_id, motion_acc, time_step, dt, paused, motion_data_keys, info_display_interval, motion_data
    device = torch.device("cpu")
    humanoid_xml = cfg.robot.asset.assetFileName
    sk_tree = SkeletonTree.from_mjcf(humanoid_xml)
    
    curr_start, num_motions, motion_id, motion_acc, time_step, dt, paused = 0, 1, 0, set(), 0, 1/30, False
    info_display_interval = 10  # ä¿¡æ¯æ˜¾ç¤ºé—´éš”å¸§æ•°
    
    motion_file = cfg.get("motion_file", f"{cfg.output_path}/{cfg.robot.humanoid_type}/motion_im.p")
    
    if not os.path.exists(motion_file):
        print(f"é”™è¯¯: è¿åŠ¨æ–‡ä»¶ä¸å­˜åœ¨: {motion_file}")
        print("è¯·å…ˆè¿è¡Œretarget_motion.pyç”Ÿæˆè¿åŠ¨æ•°æ®")
        return

    print(f"åŠ è½½è¿åŠ¨æ–‡ä»¶: {motion_file}")
    motion_data = joblib.load(motion_file)
    print(f"è¿åŠ¨æ•°æ®ç±»å‹: {type(motion_data)}")
    
    if isinstance(motion_data, dict):
        motion_data_keys = list(motion_data.keys())
    else:
        motion_data_keys = ["single_motion"]
        motion_data = {"single_motion": motion_data}
    
    print(f"æ‰¾åˆ° {len(motion_data_keys)} ä¸ªè¿åŠ¨")
    
    # å¯åŠ¨æ—¶åˆ†ææ‰€æœ‰è¿åŠ¨ç»Ÿè®¡ä¿¡æ¯
    analyze_motion_stats(motion_data)
    print("ğŸ’¡ æç¤º: æ’­æ”¾æ—¶æŒ‰Sé”®æŸ¥çœ‹å½“å‰åŠ¨ä½œçš„è¯¦ç»†ç»Ÿè®¡ï¼ŒæŒ‰Aé”®æŸ¥çœ‹æ‰€æœ‰åŠ¨ä½œç»Ÿè®¡")
    
    mj_model = mujoco.MjModel.from_xml_path(humanoid_xml)
    mj_data = mujoco.MjData(mj_model)
    
    RECORDING = False
    
    mj_model.opt.timestep = dt
    
    print("æ§åˆ¶è¯´æ˜:")
    print("  ç©ºæ ¼é”®: æš‚åœ/ç»§ç»­")
    print("  Ré”®: é‡ç½®åˆ°å¼€å§‹")
    print("  Qé”®: ä¸Šä¸€ä¸ªè¿åŠ¨")
    print("  Eé”®: ä¸‹ä¸€ä¸ªè¿åŠ¨")
    print("  Ié”®: åˆ‡æ¢Task Infoæ˜¾ç¤ºé¢‘ç‡ (æ¯10å¸§/æ¯30å¸§/æ¯å¸§)")
    print("  Sé”®: æ˜¾ç¤ºå½“å‰åŠ¨ä½œç»Ÿè®¡ä¿¡æ¯")
    print("  Aé”®: æ˜¾ç¤ºæ‰€æœ‰åŠ¨ä½œç»Ÿè®¡ä¿¡æ¯")
    print("")
    print("ğŸ”„ Task Infoæ˜¾ç¤ºé—´éš”: æ¯10å¸§")
    
    with mujoco.viewer.launch_passive(mj_model, mj_data, key_callback=key_call_back) as viewer:
        for _ in range(25):
            add_visual_capsule(viewer.user_scn, np.zeros(3), np.array([0.001, 0, 0]), 0.03, np.array([1, 0, 0, 1]))
        
        while viewer.is_running():
            step_start = time.time()
            curr_motion_key = motion_data_keys[motion_id]
            curr_motion = motion_data[curr_motion_key]
            
            max_frames = curr_motion['dof'].shape[0]
            curr_time = int(time_step/dt) % max_frames
            
            try:
                mj_data.qpos[:3] = curr_motion['root_trans_offset'][curr_time]
                mj_data.qpos[3:7] = curr_motion['root_rot'][curr_time][[3, 0, 1, 2]]
                # mj_data.qpos[7:] = curr_motion['dof'][curr_time]
                mj_data.qpos[7:] = curr_motion['dof_increment'][curr_time] + curr_motion['default_joint_angles']
            except IndexError as e:
                print(f"æ•°æ®ç´¢å¼•é”™è¯¯: {e}, curr_time={curr_time}, max_frames={max_frames}")
                time_step = 0
                continue
                
            mujoco.mj_forward(mj_model, mj_data)
            if not paused:
                time_step += dt

            # æ ¹æ®è®¾ç½®çš„é—´éš”æ˜¾ç¤ºtask_info
            if curr_time % info_display_interval == 0:
                print(f"\n{'='*50}")
                print(f"ğŸ¬ åŠ¨ä½œ: {curr_motion_key}")
                print(f"ğŸ“ å¸§: {curr_time}/{max_frames} | æ—¶é—´: {curr_time/30:.2f}s")
                
                # æ˜¾ç¤ºtask_infoä¿¡æ¯
                if 'task_info' in curr_motion:
                    task_info = curr_motion['task_info']
                    if curr_time < len(task_info['target_vel']):
                        target_vel = task_info['target_vel'][curr_time]
                        motion_type = task_info['motion_type'][curr_time]
                        
                        # è¿åŠ¨ç±»å‹åç§°æ˜ å°„
                        motion_type_names = {
                            0: "åŸåœ°è¸æ­¥", 1: "å·¦è½¬è¡Œèµ°", 2: "å³è½¬è¡Œèµ°", 3: "ç›´çº¿è¡Œèµ°",
                            4: "å·¦è½¬è·‘æ­¥", 5: "å³è½¬è·‘æ­¥", 6: "ç›´çº¿è·‘æ­¥", 
                            7: "ç«™ç«‹", 8: "è¹²ä¸‹", 9: "æœªçŸ¥"
                        }
                        type_name = motion_type_names.get(motion_type, f"ç±»å‹{motion_type}")
                        
                        print(f"ğŸ¯ å½“å‰å¸§é€Ÿåº¦:")
                        print(f"   å‰è¿›: {target_vel[0]:+6.3f} m/s | æ¨ªå‘: {target_vel[1]:+6.3f} m/s | è½¬å‘: {target_vel[2]:+6.3f} rad/s")
                        
                        # è®¡ç®—æ€»é€Ÿåº¦
                        speed = np.sqrt(target_vel[0]**2 + target_vel[1]**2)
                        print(f"   æ€»é€Ÿåº¦: {speed:6.3f} m/s")
                        
                        print(f"ğŸƒ è¿åŠ¨ç±»å‹: {motion_type} ({type_name})")
                        
                        # æ˜¾ç¤ºè¿™ä¸ªåŠ¨ä½œçš„æ•´ä½“ç»Ÿè®¡ (ç®€åŒ–ç‰ˆ)
                        all_vel = task_info['target_vel']
                        all_types = task_info['motion_type']
                        max_speed = np.max(np.sqrt(all_vel[:, 0]**2 + all_vel[:, 1]**2))
                        max_turn = np.max(np.abs(all_vel[:, 2]))
                        
                        type_counts = Counter(all_types)
                        most_common_type = type_counts.most_common(1)[0]
                        most_common_name = motion_type_names.get(most_common_type[0], f"ç±»å‹{most_common_type[0]}")
                        
                        print(f"ğŸ“Š æ•´ä½“ç»Ÿè®¡: æœ€å¤§é€Ÿåº¦={max_speed:.2f}m/s | æœ€å¤§è½¬é€Ÿ={max_turn:.2f}rad/s | ä¸»è¦ç±»å‹={most_common_name}({most_common_type[1]}å¸§)")
                        
                else:
                    print("âŒ æ— task_infoæ•°æ®")
                    
                if cfg.get("debug", False):
                    print(f"ğŸ¤– æ ¹ä½ç½®: [{mj_data.qpos[0]:.3f}, {mj_data.qpos[1]:.3f}, {mj_data.qpos[2]:.3f}]")
                    if 'root_height' in curr_motion:
                        print(f"ğŸ“ æ ¹é«˜åº¦: {curr_motion['root_height'][curr_time]:.3f}")
                
                print(f"{'='*50}")

            joint_gt = motion_data[curr_motion_key]['smpl_joints']
            max_joints = min(joint_gt.shape[1], len(viewer.user_scn.geoms))
            for i in range(max_joints):
                if i < len(viewer.user_scn.geoms):
                    viewer.user_scn.geoms[i].pos = joint_gt[curr_time, i]

            viewer.sync()
            
            time_until_next_step = mj_model.opt.timestep - (time.time() - step_start)
            if time_until_next_step > 0:
                time.sleep(time_until_next_step)

if __name__ == "__main__":
    main()

